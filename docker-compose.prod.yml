# ============================================
# DemeterAI v2.0 - Production Docker Compose
# ============================================
# USAGE:
#   docker-compose -f docker-compose.prod.yml up -d
#
# IMPORTANT:
#   - Set all environment variables in .env.production
#   - Never use default passwords in production
#   - Enable SSL/TLS for external connections
#   - Configure backup strategies for volumes
# ============================================

services:
  # ==========================================
  # PostgreSQL 18 + PostGIS 3.6 (Production)
  # ==========================================
  db:
    image: postgis/postgis:18-3.6
    container_name: demeterai-db-prod
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      # Production performance tuning
      POSTGRES_SHARED_BUFFERS: 1GB
      POSTGRES_EFFECTIVE_CACHE_SIZE: 4GB
      POSTGRES_MAX_CONNECTIONS: 200
    ports:
      # DO NOT expose to public internet - use internal network only
      - "127.0.0.1:5432:5432"
    volumes:
      - postgres_prod_data:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    restart: always
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 4G
        reservations:
          cpus: '2'
          memory: 2G
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
        compress: "true"

  # ==========================================
  # Redis 7 - Production Cache & Broker
  # ==========================================
  redis:
    image: redis:7-alpine
    container_name: demeterai-redis-prod
    command: >
      redis-server
      --appendonly yes
      --maxmemory 2gb
      --maxmemory-policy allkeys-lru
      --requirepass ${REDIS_PASSWORD}
    ports:
      # DO NOT expose to public internet
      - "127.0.0.1:6379:6379"
    volumes:
      - redis_prod_data:/data
    healthcheck:
      test: [ "CMD", "redis-cli", "--raw", "incr", "ping" ]
      interval: 5s
      timeout: 3s
      retries: 5
      start_period: 10s
    restart: always
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "3"
        compress: "true"

  # ==========================================
  # FastAPI Application - Production
  # ==========================================
  api:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        APP_ENV: production
    container_name: demeterai-api-prod
    ports:
      # Expose on localhost only - use reverse proxy (nginx/traefik) for external access
      - "127.0.0.1:8000:8000"
    env_file:
      - .env.production
    environment:
      # Database configuration
      - DATABASE_URL=postgresql+asyncpg://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}
      - DATABASE_URL_SYNC=postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}
      - DB_POOL_SIZE=30
      - DB_MAX_OVERFLOW=20
      - DB_ECHO_SQL=false
      # Redis & Celery
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
      - CELERY_BROKER_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
      - CELERY_RESULT_BACKEND=redis://:${REDIS_PASSWORD}@redis:6379/1
      # Logging - WARNING level for production
      - LOG_LEVEL=WARNING
      - DEBUG=false
      # OpenTelemetry configuration
      - OTEL_ENABLED=${OTEL_ENABLED:-true}
      - OTEL_EXPORTER_OTLP_ENDPOINT=${OTEL_EXPORTER_OTLP_ENDPOINT}
      - OTEL_SERVICE_NAME=demeterai-api
      - APP_ENV=production
      # Auth0 configuration
      - AUTH0_DOMAIN=${AUTH0_DOMAIN}
      - AUTH0_API_AUDIENCE=${AUTH0_API_AUDIENCE}
      - AUTH0_ALGORITHMS=RS256
      # S3 configuration
      - AWS_REGION=${AWS_REGION}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - S3_BUCKET_ORIGINAL=${S3_BUCKET_ORIGINAL}
      - S3_BUCKET_VISUALIZATION=${S3_BUCKET_VISUALIZATION}
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/health" ]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 60s
    restart: always
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 1G
      # Restart policy for production
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
        compress: "true"

  # ==========================================
  # Celery CPU Worker (Production)
  # ==========================================
  celery_cpu:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        APP_ENV: production
    container_name: demeterai-celery-cpu-prod
    env_file:
      - .env.production
    environment:
      - DATABASE_URL=postgresql+asyncpg://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}
      - DATABASE_URL_SYNC=postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
      - CELERY_BROKER_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
      - CELERY_RESULT_BACKEND=redis://:${REDIS_PASSWORD}@redis:6379/1
      - LOG_LEVEL=WARNING
      - DEBUG=false
      - OTEL_ENABLED=${OTEL_ENABLED:-true}
      - OTEL_EXPORTER_OTLP_ENDPOINT=${OTEL_EXPORTER_OTLP_ENDPOINT}
      - OTEL_SERVICE_NAME=demeterai-celery-cpu
      - APP_ENV=production
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: always
    deploy:
      resources:
        limits:
          cpus: '6'
          memory: 6G
        reservations:
          cpus: '2'
          memory: 2G
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
        compress: "true"
    command: celery -A app.celery_app worker --pool=prefork --concurrency=4 --queues=cpu_queue --loglevel=warning

  # ==========================================
  # Celery I/O Worker (Production)
  # ==========================================
  celery_io:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        APP_ENV: production
    container_name: demeterai-celery-io-prod
    env_file:
      - .env.production
    environment:
      - DATABASE_URL=postgresql+asyncpg://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}
      - DATABASE_URL_SYNC=postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
      - CELERY_BROKER_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
      - CELERY_RESULT_BACKEND=redis://:${REDIS_PASSWORD}@redis:6379/1
      - LOG_LEVEL=WARNING
      - DEBUG=false
      - OTEL_ENABLED=${OTEL_ENABLED:-true}
      - OTEL_EXPORTER_OTLP_ENDPOINT=${OTEL_EXPORTER_OTLP_ENDPOINT}
      - OTEL_SERVICE_NAME=demeterai-celery-io
      - APP_ENV=production
    depends_on:
      redis:
        condition: service_healthy
    restart: always
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
        compress: "true"
    command: celery -A app.celery_app worker --pool=gevent --concurrency=50 --queues=io_queue --loglevel=warning

  # ==========================================
  # Flower - Celery Monitoring (Production)
  # ==========================================
  flower:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        APP_ENV: production
    container_name: demeterai-flower-prod
    ports:
      # DO NOT expose to public internet - use VPN or IP whitelist
      - "127.0.0.1:5555:5555"
    env_file:
      - .env.production
    environment:
      - CELERY_BROKER_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
      - CELERY_RESULT_BACKEND=redis://:${REDIS_PASSWORD}@redis:6379/1
      - FLOWER_BASIC_AUTH=${FLOWER_USER}:${FLOWER_PASSWORD}
    depends_on:
      redis:
        condition: service_healthy
    restart: always
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "3"
        compress: "true"
    command: celery -A app.celery_app flower --port=5555 --url_prefix=flower

  # ==========================================
  # OpenTelemetry Collector (Production)
  # ==========================================
  otel-collector:
    image: otel/opentelemetry-collector-contrib:latest
    container_name: demeterai-otel-collector-prod
    command: [ "--config=/etc/otel-collector-config.yaml" ]
    ports:
      - "127.0.0.1:4317:4317"   # OTLP gRPC receiver
      - "127.0.0.1:4318:4318"   # OTLP HTTP receiver
      - "127.0.0.1:8888:8888"   # Prometheus metrics
    volumes:
      - ./otel-collector-config.yaml:/etc/otel-collector-config.yaml:ro
    restart: always
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "3"
        compress: "true"

  # ==========================================
  # Prometheus (Production)
  # ==========================================
  prometheus:
    image: prom/prometheus:latest
    container_name: demeterai-prometheus-prod
    ports:
      - "127.0.0.1:9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_prod_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    restart: always
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "3"
        compress: "true"

  # ==========================================
  # Grafana (Production)
  # ==========================================
  grafana:
    image: grafana/grafana:latest
    container_name: demeterai-grafana-prod
    ports:
      - "127.0.0.1:3000:3000"
    volumes:
      - grafana_prod_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
      - GF_SERVER_ROOT_URL=${GRAFANA_ROOT_URL}
      - GF_ANALYTICS_REPORTING_ENABLED=false
      - GF_ANALYTICS_CHECK_FOR_UPDATES=false
    restart: always
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "3"
        compress: "true"

volumes:
  postgres_prod_data:
    driver: local
  redis_prod_data:
    driver: local
  prometheus_prod_data:
    driver: local
  grafana_prod_data:
    driver: local

networks:
  default:
    name: demeterai-network-prod
    driver: bridge
