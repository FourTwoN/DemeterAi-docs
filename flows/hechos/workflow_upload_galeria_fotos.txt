Ahora vamos a ver el workflow que tiene que ver con el tema de las fotos.
Es decir, todo lo que tiene que ver con la subida y la visualización siguiente.
Entonces tenemos una vista donde nosotros vamos a subir las fotos.
Esto que va a ser generar los jobs, digamos, de procesamiento.
Entonces acá uno lo que hace como usuario agarra las 100 fotos que sacó, las carga.
Entonces las envía por multipart file a nuestro backend.
Nosotros las guardamos en un directorio temporal y le devolvemos que hemos recibido correctamente las fotos y que las estamos procesando.
Entonces justo debajo de esta vista estaría una lista de los jobs o tareas de estas 100 fotos.
Que es decir, habría una como una falsa barra de carga donde el frontend mostraría como que está en proceso.
Como cada uno puede tardar entre 5 a 10 minutos o menos, dependiendo el hardware que utilicemos.
El frontend debería mostrar que sí, se están procesando.
Entonces esta lista de jobs que nuestro Celery estaría ejecutando.
Que serían los UID de las distintas fotos y qué seró.
Estaría cargando.
Una vez que termine o el frontend refresque cada 5 minutos o el usuario cliquee refrescar.
Esta lista de jobs se mostrará por 24 horas o 48 horas.
Eso se puede ver.
Entonces nosotros deberíamos poder ser capaces de devolverle los últimos jobs de las 48 horas.
Y de ser completado con éxito el job.
El usuario podría cliquear dentro del job y mostrarle el mismo side panel que le mostramos cuando vemos el detalle de un storage location.
Entonces le mostraríamos la foto, las detecciones que sacó porque se completó el job con éxito y los mismos detalles que le mostramos en el otro lado.
Ese sería la vista de subir las fotos y el procesamiento.
O sea que el usuario pueda ver qué está pasando con las fotos que subió.
Y después tendríamos otra vista que sería la galería de fotos.
Acá es donde el usuario puede ver todas las fotos que ha subido a lo largo del tiempo.
Esto es con las thumbnails de S3.
Podría el usuario ver todo lo que ha pasado.
Y acá es donde entra en juego las fotos con advertencias o errores.
Es decir, si por ejemplo no tuvo data de GPS o no había configuración de claro.
O tenía data de GPS pero no pudimos ubicarla.
El usuario podría intentar salvar esa excepción que nosotros tuvimos.
Es decir, por ejemplo, que no tiene configuración el claro a donde está asociada esta foto.
Bueno, el usuario podría, según esta foto, ir y agregar la configuración que falta para el claro correspondiente.
Y la foto se mandaría a reprocesar.
Como nosotros en el S3 tendríamos subida a la foto original, deberíamos mandar a procesar directamente al pipeline de Machine Learning que teníamos anteriormente.
Entonces, directamente nos salteamos la parte de subir la imagen original al S3 y la procesaríamos.
Haríamos las detecciones y salvaríamos las excepciones.
Entonces, en esta galería de fotos, el usuario debería ver todas las fotos que ha subido.
Originales y podría cliquear y ver el detalle de Storage Location como vimos anteriormente.
Entonces, el que tiene el historial y trazabilidad, no el side panel.
O sea, el más completo de todos, si fuese con éxito la foto.
Entonces, podría entrar y ver las detecciones que se hicieron y toda la información que presentamos en el otro lado.
Y así tendríamos la galería de fotos para salvar errores o ver las fotos que hemos ido subiendo.
Y si se quiere eliminar fotos, por ejemplo, que se haya subido alguna mal o lo que sea, también se puede eliminar.
Y tendríamos estas dos vistas, subir fotos y galería de fotos.
