# ============================================
# DemeterAI v2.0 - Docker Compose Configuration
# ============================================
#
# BUILD OPTIMIZATION NOTES:
# -------------------------
# 1. Single image build: All services use `demeterai-base:latest` to avoid
#    rebuilding the same image 5 times (saves ~400s per build)
#
# 2. BuildKit cache: The `api` service has `cache_from` configured to reuse
#    previous build layers. Enable BuildKit for best performance:
#    $ export DOCKER_BUILDKIT=1
#    $ export COMPOSE_DOCKER_CLI_BUILD=1
#
# 3. Development workflow tips:
#    - For code changes only: `docker compose restart <service>`
#    - For dependency changes: `docker compose build --no-cache api && docker compose up -d`
#    - FastAPI auto-reload is enabled (--reload flag) for instant code updates
#    - Use bind mounts (see commented section below) for even faster iteration
#
# 4. Pre-pull base images to save time:
#    $ docker pull python:3.12-slim
#    $ docker pull postgis/postgis:18-3.6
#    $ docker pull redis:7-alpine
#
# ============================================

services:
  # ==========================================
  # PostgreSQL 18 + PostGIS 3.6 (Development)
  # ==========================================
  db:
    image: postgis/postgis:18-3.6
    container_name: demeterai-db
    environment:
      POSTGRES_USER: demeter
      POSTGRES_PASSWORD: demeter_dev_password
      POSTGRES_DB: demeterai
      # Performance tuning for development
      POSTGRES_SHARED_BUFFERS: 256MB
      POSTGRES_EFFECTIVE_CACHE_SIZE: 1GB
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U demeter -d demeterai" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ==========================================
  # PostgreSQL 18 + PostGIS 3.6 (Testing)
  # ==========================================
  db_test:
    image: postgis/postgis:18-3.6
    container_name: demeterai-db-test
    environment:
      POSTGRES_USER: demeter_test
      POSTGRES_PASSWORD: demeter_test_password
      POSTGRES_DB: demeterai_test
      # Performance tuning for testing
      POSTGRES_SHARED_BUFFERS: 128MB
      POSTGRES_EFFECTIVE_CACHE_SIZE: 512MB
    ports:
      - "5434:5432"  # Different port to avoid conflicts
    volumes:
      - postgres_test_data:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U demeter_test -d demeterai_test" ]
      interval: 5s
      timeout: 3s
      retries: 5
      start_period: 5s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # ==========================================
  # Redis 7 - Cache & Celery Broker
  # ==========================================
  redis:
    image: redis:7-alpine
    container_name: demeterai-redis
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 5s
      timeout: 3s
      retries: 5
      start_period: 5s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # ==========================================
  # FastAPI Application - Development Mode
  # ==========================================
  # BUILD OPTIMIZATION: This service builds the base image once and tags it as
  # `demeterai-base:latest`. All other services reuse this image to avoid
  # redundant builds (saves ~10 minutes on full rebuild).
  # ==========================================
  api:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        APP_ENV: development
      cache_from:
        - demeterai-base:latest
    image: demeterai-base:latest
    container_name: demeterai-api
    ports:
      - "8000:8000"
    # OPTIONAL: For ultra-fast development, uncomment bind mounts below to get
    # instant code updates without rebuilding. Requires commenting out the
    # corresponding COPY commands in Dockerfile.
    # volumes:
    #   - ./app:/app/app:ro              # Application code (read-only)
    #   - ./alembic:/app/alembic:ro      # Alembic migrations (read-only)
    #   - ./scripts:/app/scripts:ro      # Helper scripts (read-only)
    env_file:
      - .env
    environment:
      # Database configuration
      - DATABASE_URL=postgresql+asyncpg://demeter:demeter_dev_password@db:5432/demeterai
      - DATABASE_URL_SYNC=postgresql+psycopg2://demeter:demeter_dev_password@db:5432/demeterai
      - DB_POOL_SIZE=20
      - DB_MAX_OVERFLOW=10
      - DB_ECHO_SQL=false
      - LOAD_PRODUCTION_DATA=true
      # Redis & Celery
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/1
      # Logging
      - LOG_LEVEL=DEBUG
      - DEBUG=true
      # OpenTelemetry configuration (pointing to LGTM container gRPC endpoint)
      - OTEL_ENABLED=true
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://lgtm-demeter:4317
      - OTEL_SERVICE_NAME=demeterai-api
      - APP_ENV=development
      # Auth0 configuration (override with .env)
      - AUTH0_DOMAIN=${AUTH0_DOMAIN:-}
      - AUTH0_API_AUDIENCE=${AUTH0_API_AUDIENCE:-}
      - AUTH0_ALGORITHMS=${AUTH0_ALGORITHMS:-["RS256"]}
      # S3 configuration (override with .env)
      - AWS_REGION=${AWS_REGION:-us-east-1}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID:-}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY:-}
      - S3_BUCKET_ORIGINAL=${S3_BUCKET_ORIGINAL:-demeter-photos-original}
      - S3_BUCKET_VISUALIZATION=${S3_BUCKET_VISUALIZATION:-demeter-photos-viz}
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/health" ]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload --log-level debug

  # ==========================================
  # Celery CPU Worker (Prefork Pool)
  # ==========================================
  # BUILD OPTIMIZATION: Reuses demeterai-base:latest (no rebuild needed)
  # ==========================================
  celery_cpu:
    image: demeterai-base:latest
    container_name: demeterai-celery-cpu
    env_file:
      - .env
    environment:
      - DATABASE_URL=postgresql+asyncpg://demeter:demeter_dev_password@db:5432/demeterai
      - DATABASE_URL_SYNC=postgresql+psycopg2://demeter:demeter_dev_password@db:5432/demeterai
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/1
      - PYTHONPATH=/app
      # OpenTelemetry configuration (pointing to LGTM container)
      - OTEL_ENABLED=true
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://lgtm-demeter:4317
      - OTEL_SERVICE_NAME=demeterai-celery-cpu
      - APP_ENV=development
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    command: python /app/scripts/start_celery_worker.py

  # ==========================================
  # Celery GPU Worker (Solo Pool) - CPU-Based for Development
  # ==========================================
  # In production, this runs on GPU hardware with pool=solo
  # For development/testing on CPU-only machines, uses pool=solo with single process
  # BUILD OPTIMIZATION: Reuses demeterai-base:latest (no rebuild needed)
  # ==========================================
  celery_gpu:
    image: demeterai-base:latest
    container_name: demeterai-celery-gpu
    env_file:
      - .env
    environment:
      - DATABASE_URL=postgresql+asyncpg://demeter:demeter_dev_password@db:5432/demeterai
      - DATABASE_URL_SYNC=postgresql+psycopg2://demeter:demeter_dev_password@db:5432/demeterai
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/1
      - PYTHONPATH=/app
      # OpenTelemetry configuration
      - OTEL_ENABLED=true
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://lgtm-demeter:4317
      - OTEL_SERVICE_NAME=demeterai-celery-gpu
      - APP_ENV=development
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    # Solo pool: single process (required for GPU/CUDA, safe for CPU testing)
    # Concurrency=1: no parallel processing in this process
    command: celery -A app.celery_app worker --pool=solo --concurrency=1 --queues=gpu_queue --loglevel=info

  # ==========================================
  # Celery I/O Worker (Gevent Pool)
  # ==========================================
  # BUILD OPTIMIZATION: Reuses demeterai-base:latest (no rebuild needed)
  # ==========================================
  celery_io:
    image: demeterai-base:latest
    container_name: demeterai-celery-io
    env_file:
      - .env
    environment:
      - DATABASE_URL=postgresql+asyncpg://demeter:demeter_dev_password@db:5432/demeterai
      - DATABASE_URL_SYNC=postgresql+psycopg2://demeter:demeter_dev_password@db:5432/demeterai
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/1
      # OpenTelemetry configuration (pointing to LGTM container)
      - OTEL_ENABLED=true
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://lgtm-demeter:4317
      - OTEL_SERVICE_NAME=demeterai-celery-io
      - APP_ENV=development
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped
    command: celery -A app.celery_app worker --pool=gevent --concurrency=20 --queues=io_queue --loglevel=info

  # ==========================================
  # Flower (Celery Monitoring)
  # ==========================================
  # BUILD OPTIMIZATION: Reuses demeterai-base:latest (no rebuild needed)
  # ==========================================
  flower:
    image: demeterai-base:latest
    container_name: demeterai-flower
    ports:
      - "5555:5555"
    env_file:
      - .env
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/1
      # OpenTelemetry configuration (pointing to LGTM container)
      - OTEL_ENABLED=true
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://lgtm-demeter:4317
      - OTEL_SERVICE_NAME=demeterai-flower
      - APP_ENV=development
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped
    command: celery -A app.celery_app flower --port=5555

  # ==========================================
  # OpenTelemetry Collector (Optional - Sprint 05)
  # ==========================================
  # otel-collector:
  #   image: otel/opentelemetry-collector-contrib:latest
  #   container_name: demeterai-otel-collector
  #   command: ["--config=/etc/otel-collector-config.yaml"]
  #   ports:
  #     - "4317:4317"   # OTLP gRPC receiver
  #     - "4318:4318"   # OTLP HTTP receiver
  #     - "8888:8888"   # Prometheus metrics exposed by collector
  #     - "8889:8889"   # Prometheus exporter
  #   volumes:
  #     - ./otel-collector-config.yaml:/etc/otel-collector-config.yaml
  #   restart: unless-stopped
  #   deploy:
  #     resources:
  #       limits:
  #         cpus: '0.5'
  #         memory: 512M
  #       reservations:
  #         cpus: '0.1'
  #         memory: 128M
  #   logging:
  #     driver: "json-file"
  #     options:
  #       max-size: "5m"
  #       max-file: "2"

  # ==========================================
  # Prometheus (Sprint 05 - Optional Now)
  # ==========================================
  # prometheus:
  #   image: prom/prometheus:latest
  #   container_name: demeterai-prometheus
  #   ports:
  #     - "9090:9090"
  #   volumes:
  #     - ./prometheus.yml:/etc/prometheus/prometheus.yml
  #     - prometheus_data:/prometheus
  #   restart: unless-stopped
  #   deploy:
  #     resources:
  #       limits:
  #         cpus: '0.5'
  #         memory: 512M
  #       reservations:
  #         cpus: '0.1'
  #         memory: 128M
  #   logging:
  #     driver: "json-file"
  #     options:
  #       max-size: "5m"
  #       max-file: "2"

  # ==========================================
  # Grafana (Sprint 05 - Optional Now)
  # ==========================================
  # grafana:
  #   image: grafana/grafana:latest
  #   container_name: demeterai-grafana
  #   ports:
  #     - "3000:3000"
  #   volumes:
  #     - grafana_data:/var/lib/grafana
  #   environment:
  #     - GF_SECURITY_ADMIN_PASSWORD=admin
  #   restart: unless-stopped
  #   deploy:
  #     resources:
  #       limits:
  #         cpus: '0.5'
  #         memory: 512M
  #       reservations:
  #         cpus: '0.1'
  #         memory: 128M
  #   logging:
  #     driver: "json-file"
  #     options:
  #       max-size: "5m"
  #       max-file: "2"

volumes:
  postgres_data:
  postgres_test_data:
  redis_data:
  # prometheus_data:
  # grafana_data:

networks:
  default:
    name: demeterai-network
